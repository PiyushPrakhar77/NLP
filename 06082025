import re

# Contraction handling dictionary
contractions_dict = {
    "can't": "cannot",
    "i'm": "i am",
    "i've": "i have",
    "i'd": "i would",
    "i'll": "i will",
    "you're": "you are",
    "you've": "you have",
    "you'd": "you would",
    "you'll": "you will",
    "it's": "it is",
    "that's": "that is",
    "there's": "there is",
    "let's": "let us",
    "won't": "will not",
    "don't": "do not",
    "didn't": "did not",
    "doesn't": "does not",
    "isn't": "is not",
    "aren't": "are not",
    "wasn't": "was not",
    "weren't": "were not",
    "couldn't": "could not",
    "shouldn't": "should not",
    "wouldn't": "would not",
    "<3": "love",
    "u": "you",
    "ur": "your",
    "waz": "was",
    "plzzzz": "please",
    "bruh": "brother"
}

def expand_contractions(text):
    pattern = re.compile(r'\b(' + '|'.join(contractions_dict.keys()) + r')\b')
    return pattern.sub(lambda x: contractions_dict[x.group()], text)

def clean_text(text):
    # 1. Lowercasing
    text = text.lower()

    # 2. Handling contractions
    text = expand_contractions(text)

    # 3. Removing URL artifacts
    text = re.sub(r'http\S+|www\.\S+', '', text)

    # 4. Removing special characters except basic punctuation
    text = re.sub(r'[^a-z0-9\s\.\,\!\?]', '', text)

    # 5. Reducing duplicate letters (keeping max two)
    text = re.sub(r'(.)\1{2,}', r'\1\1', text)

    # 6. Fixing excessive punctuation
    text = re.sub(r'([!?.,])\1+', r'\1', text)

    # 7. Removing extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()

    return text


# Uncleaned paragraphs
paragraphs = [
    "whoaaaa �� this article on AI & ethics issss fireeee!!! i mean, wowww, the way it talks about robotssss takin’ over da world? lollll ������ so craaazy! found it at www.robotnews.com//// 4 real, u gotta read ittt!!! @@@ #scarybutcool #futuristicttt",
    "can&#39;tttt evennnn with this new techppp blog... sooo muchhh info jam-packed in one loooong posttttt ����!! but the way itzz writtennn… nahhh bruh. full of typos, emoji overload ����, and weirddddd punctuationnnn like !!!!!!????!!! find it at www.techmessy.io////",
    "A.I. is changinnn’ da worldd, fam!! ��✨ like everyyy single aspect of lifeee—workkk, healthhh, educashun ������!! dis article: \"how AI gonna make u smarterrrr\" waz LIT ������. got it from www.getsmartai.com//// plzzzz fix the grammerz tho #looolz @@@!!!!",
    "omg omg omg ����!! dat post on generative AI + music just BLEW MY HEADDD OFF!! �������� no joke!!! \"beethovennnn with beats\" lol whattt evennnn ���� #nextlevel. saw it on www.genmusic.art//// so so many randomnn letterssss & symbols #@#@# ��",
    "lolz!!! u ever read sumthing n feel dumberrrr after??? ���� this blog on AI bias had soooo manyyyy errorsss, like spellingggg, grammerzz, and weird layout @@@%%%... i had to squinttttt. check dis out: www.wacksource.ai//// but read at ur own risk"
]

# Clean each paragraph
cleaned_paragraphs = [clean_text(p) for p in paragraphs]

# Output cleaned text
for i, cp in enumerate(cleaned_paragraphs, 1):
    print(f"Cleaned Paragraph {i}:\n{cp}\n")

